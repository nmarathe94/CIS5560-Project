{"cells":[{"cell_type":"markdown","source":["## Final Project - Desicion Tree Classifier"],"metadata":{}},{"cell_type":"markdown","source":["### Prepare the Data\n\nFirst, import the libraries you will need and prepare the training and test data:"],"metadata":{}},{"cell_type":"code","source":["# Import Spark SQL and Spark ML libraries\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n"],"metadata":{"collapsed":false,"scrolled":false},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["### Read your csv file from its table at Databricks"],"metadata":{}},{"cell_type":"code","source":["# Load the source data\ncsv = sqlContext.sql(\"SELECT * FROM final_csv\")"],"metadata":{"collapsed":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Select features and label\ndata1 = csv.select(\"tract_to_msamd_income\",\"population\", \"minority_population\", \"loan_amount_000s\", \"applicant_income_000s\",\"purchaser_type_name\",\"preapproval_name\",\"owner_occupancy_name\",\"loan_type_name\",\"lien_status_name\",\"co_applicant_sex_name\",\"co_applicant_race_name_1\",\"co_applicant_ethnicity_name\",\"agency_name\",\"agency_abbr\",col(\"action_taken_name\").alias(\"label\"))"],"metadata":{"collapsed":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Drop rows from the table even if one value is null\ndata2 = data1.dropna()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Split the data\nsplits = data2.randomSplit([0.7, 0.3])\ntrain = splits[0]\ntest = splits[1].withColumnRenamed(\"label\", \"trueLabel\")"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["### Define the Pipeline\nNow define a pipeline that creates a feature vector and trains a classification model"],"metadata":{}},{"cell_type":"code","source":["vectorAssembler = VectorAssembler(inputCols = [\"tract_to_msamd_income\",\"population\", \"minority_population\", \"loan_amount_000s\", \"applicant_income_000s\",\"purchaser_type_name\",\"preapproval_name\",\"owner_occupancy_name\",\"loan_type_name\",\"lien_status_name\",\"co_applicant_sex_name\",\"co_applicant_race_name_1\",\"co_applicant_ethnicity_name\",\"agency_name\",\"agency_abbr\"], outputCol=\"features\")\n#Model1 - Decision Tree \ndecision = DecisionTreeClassifier(labelCol=\"label\", featuresCol= \"features\")\npipeline = Pipeline(stages=[vectorAssembler, decision])"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["### Train the Model"],"metadata":{}},{"cell_type":"code","source":["# define list of models made from Train Validation Split and Cross Validation\nmodel = pipeline.fit(train)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["### Test the Model\nNow you're ready to apply the model to the test data."],"metadata":{}},{"cell_type":"code","source":["prediction = model.transform(test)\npredicted = prediction.select(\"prediction\", \"trueLabel\")"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["### Review the Area Under ROC\nAnother way to assess the performance of a classification model is to measure the area under a ROC curve for the model. the spark.ml library includes a **BinaryClassificationEvaluator** class that you can use to compute this."],"metadata":{}},{"cell_type":"code","source":["evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\nauc = evaluator.evaluate(prediction)\nprint \"Average Accuracy =\", auc"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["### Review the Recall And Precision\nAnother way to assess the performance of a classification model is to measure the area under a ROC curve for the model. the spark.ml library includes a **BinaryClassificationEvaluator** class that you can use to compute this."],"metadata":{}},{"cell_type":"code","source":["tp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 1\").count())\nfp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 0\").count())\ntn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 0\").count())\nfn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 1\").count())\nmetrics = spark.createDataFrame([(\"Precision\", tp / (tp + fp)), (\"Recall\", tp / (tp + fn))],[\"metric\", \"value\"])\nmetrics.show()"],"metadata":{},"outputs":[],"execution_count":18}],"metadata":{"kernelspec":{"display_name":"Python 2 with Spark 2.0","language":"python","name":"python2-spark20"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.11","nbconvert_exporter":"python","file_extension":".py"},"name":"Midterm2 Python+Classfication+Parameter+Tuning","notebookId":1156836972103890},"nbformat":4,"nbformat_minor":0}

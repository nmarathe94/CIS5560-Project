{"cells":[{"cell_type":"markdown","source":["## Final Project - Logistic Regression"],"metadata":{}},{"cell_type":"markdown","source":["### Prepare the Data\n\nFirst, import the libraries you will need and prepare the training and test data:"],"metadata":{}},{"cell_type":"code","source":["# Import Spark SQL and Spark ML libraries\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n"],"metadata":{"collapsed":false,"scrolled":false},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["### Read your csv file from its table at Databricks"],"metadata":{}},{"cell_type":"code","source":["# Load the source data\ncsv = sqlContext.sql(\"SELECT * FROM final_csv\")"],"metadata":{"collapsed":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# Select features and label\ndata1 = csv.select(\"tract_to_msamd_income\",\"population\", \"minority_population\", \"loan_amount_000s\", \"applicant_income_000s\",\"purchaser_type_name\",\"preapproval_name\",\"owner_occupancy_name\",\"loan_type_name\",\"lien_status_name\",\"co_applicant_sex_name\",\"co_applicant_race_name_1\",\"co_applicant_ethnicity_name\",\"agency_name\",\"agency_abbr\",col(\"action_taken_name\").alias(\"label\"))"],"metadata":{"collapsed":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Drop rows from the table even if one value is null\ndata2 = data1.dropna()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# Split the data\nsplits = data2.randomSplit([0.7, 0.3])\ntrain = splits[0]\ntest = splits[1].withColumnRenamed(\"label\", \"trueLabel\")"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["### Define the Pipeline\nNow define a pipeline that creates a feature vector and trains a classification model"],"metadata":{}},{"cell_type":"code","source":["# Define the pipeline\nlr = []\npipeline = []\nassembler = []\nfor i in range(2):\n  assembler.insert(i, VectorAssembler(inputCols = [\"tract_to_msamd_income\",\"population\", \"minority_population\", \"loan_amount_000s\", \"applicant_income_000s\",\"purchaser_type_name\",\"preapproval_name\",\"owner_occupancy_name\",\"loan_type_name\",\"lien_status_name\",\"co_applicant_sex_name\",\"co_applicant_race_name_1\",\"co_applicant_ethnicity_name\",\"agency_name\",\"agency_abbr\"], outputCol=\"features\"))\n  lr.insert(i, LogisticRegression(labelCol=\"label\", featuresCol=\"features\"))\n  pipeline.insert(i, Pipeline(stages=[assembler[i], lr[i]]))"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["### Train Validation Split with Threshold parameters\nBuild the best model using TrainValidationSplit"],"metadata":{}},{"cell_type":"markdown","source":["The first combination of parameters with (regParam: [0.01, 0.5]), (threshold: [0.30, 0.35]), (maxIter: [1, 5])"],"metadata":{}},{"cell_type":"code","source":["# define list of models made from Train Validation Split and Cross Validation\nmodel = []"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# params refered to the reference above\nparamGrid = (ParamGridBuilder() \\\n             .addGrid(lr[0].regParam, [0.01, 0.5, 2.0]) \\\n             .addGrid(lr[0].threshold, [0.30, 0.35]) \\\n             .addGrid(lr[0].maxIter, [1, 5]) \\\n             .build())"],"metadata":{"collapsed":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":["tvs = TrainValidationSplit(estimator=pipeline[0], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)\n# the first best model\nmodel.insert(0, tvs.fit(train))"],"metadata":{"collapsed":false},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":["### Train Validation Split with elastic-net parameters\nThe second combination of parameters with (regParam: [0.01, 0.5, 2.0]), (elasticNetParam: [0.0, 0.5, 1]), (maxIter: [1, 5])"],"metadata":{}},{"cell_type":"code","source":["# TODO: params refered to the reference above\nparamGrid2 = (ParamGridBuilder()\n.addGrid(lr[0].regParam, [0.01, 0.5, 2.0])\n.addGrid(lr[0].elasticNetParam, [0.0, 0.5, 1])\n.addGrid(lr[0].maxIter, [1, 5]).build())"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["tvs2 = TrainValidationSplit(estimator=pipeline[1], evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid2, trainRatio=0.8)\n\n# the second best model\nmodel.insert(1, tvs2.fit(train))"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["### Test the Model\nNow you're ready to apply the model to the test data."],"metadata":{}},{"cell_type":"code","source":["# list prediction\nprediction = [] \npredicted = []\nfor i in range(2):\n  prediction.insert(i, model[i].transform(test))\n  predicted.insert(i, prediction[i].select(\"features\", \"prediction\", \"probability\", \"trueLabel\"))\n  predicted[i].show(30)"],"metadata":{"collapsed":false,"scrolled":false},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["### Review the Area Under ROC\nAnother way to assess the performance of a classification model is to measure the area under a ROC curve for the model. the spark.ml library includes a **BinaryClassificationEvaluator** class that you can use to compute this."],"metadata":{}},{"cell_type":"code","source":["evaluator = []\nfor i in range(2):\n  evaluator.insert(i, BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\"))\n  auc = evaluator[i].evaluate(prediction[i])\n  print \"AUC \", i, \" = \", auc"],"metadata":{"collapsed":false},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["### Review the Recall And Precision"],"metadata":{}},{"cell_type":"code","source":["for i in range(2):\n  tp = float(predicted[i].filter(\"prediction == 1.0 AND truelabel == 1\").count())\n  fp = float(predicted[i].filter(\"prediction == 1.0 AND truelabel == 0\").count())\n  tn = float(predicted[i].filter(\"prediction == 0.0 AND truelabel == 0\").count())\n  fn = float(predicted[i].filter(\"prediction == 0.0 AND truelabel == 1\").count())\n  metrics = spark.createDataFrame([\n      (\"Precision\", tp / (tp + fp)),\n      (\"Recall\", tp / (tp + fn))],[\"metric\", \"value\"])\n  metrics.show()"],"metadata":{},"outputs":[],"execution_count":24}],"metadata":{"kernelspec":{"display_name":"Python 2 with Spark 2.0","language":"python","name":"python2-spark20"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2},"version":"2.7.11","nbconvert_exporter":"python","file_extension":".py"},"name":"Midterm2 Python+Classfication+Parameter+Tuning","notebookId":1156836972103921},"nbformat":4,"nbformat_minor":0}
